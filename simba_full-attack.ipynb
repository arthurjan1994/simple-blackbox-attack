{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "#Import necessary packages\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import utils\n",
    "import math\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --data_root DATA_ROOT\n",
      "                             [--result_dir RESULT_DIR]\n",
      "                             [--sampled_image_dir SAMPLED_IMAGE_DIR]\n",
      "                             [--model MODEL] [--num_runs NUM_RUNS]\n",
      "                             [--batch_size BATCH_SIZE] [--num_iters NUM_ITERS]\n",
      "                             [--log_every LOG_EVERY] [--epsilon EPSILON]\n",
      "                             [--freq_dims FREQ_DIMS] [--order ORDER]\n",
      "                             [--stride STRIDE] [--targeted] [--pixel_attack]\n",
      "                             [--save_suffix SAVE_SUFFIX]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --data_root\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#Parse arguments\n",
    "parser= argparse.ArgumentParser(description='Runs SimBA on a set of images')\n",
    "parser.add_argument('--data_root', type=str, required=True, help='root directory of imagenet data')\n",
    "parser.add_argument('--result_dir', type=str, default='save', help='directory for saving results')\n",
    "parser.add_argument('--sampled_image_dir', type=str, default='save', help='directory to cache sampled images')\n",
    "parser.add_argument('--model', type=str, default='resnet50', help='type of base model to use')\n",
    "parser.add_argument('--num_runs', type=int, default=1000, help='number of image samples')\n",
    "parser.add_argument('--batch_size', type=int, default=50, help='batch size for parallel runs')\n",
    "parser.add_argument('--num_iters', type=int, default=0, help='maximum number of iterations, 0 for unlimited')\n",
    "parser.add_argument('--log_every', type=int, default=10, help='log every n iterations')\n",
    "parser.add_argument('--epsilon', type=float, default=0.2, help='step size per iteration')\n",
    "parser.add_argument('--freq_dims', type=int, default=14, help='dimensionality of 2D frequency space')\n",
    "parser.add_argument('--order', type=str, default='rand', help='(random) order of coordinate selection')\n",
    "parser.add_argument('--stride', type=int, default=7, help='stride for block order')\n",
    "parser.add_argument('--targeted', action='store_true', help='perform targeted attack')\n",
    "parser.add_argument('--pixel_attack', action='store_true', help='attack in pixel space')\n",
    "parser.add_argument('--save_suffix', type=str, default='', help='suffix appended to save file')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some functions\n",
    "def expand_vector(x, size):\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(-1, 3, size, size)\n",
    "    z = torch.zeros(batch_size, 3, image_size, image_size)\n",
    "    z[:, :, :size, :size] = x\n",
    "    return z\n",
    "\n",
    "def normalize(x):\n",
    "    return utils.apply_normalization(x, 'imagenet')\n",
    "\n",
    "def get_probs(model, x, y):\n",
    "    output = model(normalize(torch.autograd.Variable(x.cuda()))).cpu()\n",
    "    probs = torch.index_select(torch.nn.Softmax()(output).data, 1, y)\n",
    "    return torch.diag(probs)\n",
    "\n",
    "def get_preds(model, x):\n",
    "    output = model(normalize(torch.autograd.Variable(x.cuda()))).cpu()\n",
    "    _, preds = output.data.max(1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1457b4fe0be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinf_norms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampled_image_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "#Rest of the code\n",
    "# runs simba on a batch of images <images_batch> with true labels (for untargeted attack) or target labels\n",
    "# (for targeted attack) <labels_batch>\n",
    "def dct_attack_batch(model, images_batch, labels_batch, max_iters, freq_dims, stride, epsilon, order='rand', targeted=False, pixel_attack=False, log_every=1):\n",
    "    batch_size = images_batch.size(0)\n",
    "    image_size = images_batch.size(2)\n",
    "    # sample a random ordering for coordinates independently per batch element\n",
    "    if order == 'rand':\n",
    "        indices = torch.randperm(3 * freq_dims * freq_dims)[:max_iters]\n",
    "    elif order == 'diag':\n",
    "        indices = utils.diagonal_order(image_size, 3)[:max_iters]\n",
    "    elif order == 'strided':\n",
    "        indices = utils.block_order(image_size, 3, initial_size=freq_dims, stride=stride)[:max_iters]\n",
    "    else:\n",
    "        indices = utils.block_order(image_size, 3)[:max_iters]\n",
    "    if order == 'rand':\n",
    "        expand_dims = freq_dims\n",
    "    else:\n",
    "        expand_dims = image_size\n",
    "    n_dims = 3 * expand_dims * expand_dims\n",
    "    x = torch.zeros(batch_size, n_dims)\n",
    "    # logging tensors\n",
    "    probs = torch.zeros(batch_size, max_iters)\n",
    "    succs = torch.zeros(batch_size, max_iters)\n",
    "    queries = torch.zeros(batch_size, max_iters)\n",
    "    l2_norms = torch.zeros(batch_size, max_iters)\n",
    "    linf_norms = torch.zeros(batch_size, max_iters)\n",
    "    prev_probs = get_probs(model, images_batch, labels_batch)\n",
    "    preds = get_preds(model, images_batch)\n",
    "    if pixel_attack:\n",
    "        trans = lambda z: z\n",
    "    else:\n",
    "        trans = lambda z: utils.block_idct(z, block_size=image_size)\n",
    "    remaining_indices = torch.arange(0, batch_size).long()\n",
    "    for k in range(max_iters):\n",
    "        dim = indices[k]\n",
    "        expanded = (images_batch[remaining_indices] + trans(expand_vector(x[remaining_indices], expand_dims))).clamp(0, 1)\n",
    "        perturbation = trans(expand_vector(x, expand_dims))\n",
    "        l2_norms[:, k] = perturbation.view(batch_size, -1).norm(2, 1)\n",
    "        linf_norms[:, k] = perturbation.view(batch_size, -1).abs().max(1)[0]\n",
    "        preds_next = get_preds(model, expanded)\n",
    "        preds[remaining_indices] = preds_next\n",
    "        if targeted:\n",
    "            remaining = preds.ne(labels_batch)\n",
    "        else:\n",
    "            remaining = preds.eq(labels_batch)\n",
    "        # check if all images are misclassified and stop early\n",
    "        if remaining.sum() == 0:\n",
    "            adv = (images_batch + trans(expand_vector(x, expand_dims))).clamp(0, 1)\n",
    "            probs_k = get_probs(model, adv, labels_batch)\n",
    "            probs[:, k:] = probs_k.unsqueeze(1).repeat(1, max_iters - k)\n",
    "            succs[:, k:] = torch.ones(args.batch_size, max_iters - k)\n",
    "            queries[:, k:] = torch.zeros(args.batch_size, max_iters - k)\n",
    "            break\n",
    "        remaining_indices = torch.arange(0, batch_size)[remaining].long()\n",
    "        if k > 0:\n",
    "            succs[:, k-1] = 1 - remaining\n",
    "        diff = torch.zeros(remaining.sum(), n_dims)\n",
    "        diff[:, dim] = epsilon\n",
    "        left_vec = x[remaining_indices] - diff\n",
    "        right_vec = x[remaining_indices] + diff\n",
    "        # trying negative direction\n",
    "        adv = (images_batch[remaining_indices] + trans(expand_vector(left_vec, expand_dims))).clamp(0, 1)\n",
    "        left_probs = get_probs(model, adv, labels_batch[remaining_indices])\n",
    "        queries_k = torch.zeros(batch_size)\n",
    "        # increase query count for all images\n",
    "        queries_k[remaining_indices] += 1\n",
    "        if targeted:\n",
    "            improved = left_probs.gt(prev_probs[remaining_indices])\n",
    "        else:\n",
    "            improved = left_probs.lt(prev_probs[remaining_indices])\n",
    "        # only increase query count further by 1 for images that did not improve in adversarial loss\n",
    "        if improved.sum() < remaining_indices.size(0):\n",
    "            queries_k[remaining_indices[1-improved]] += 1\n",
    "        # try positive directions\n",
    "        adv = (images_batch[remaining_indices] + trans(expand_vector(right_vec, expand_dims))).clamp(0, 1)\n",
    "        right_probs = get_probs(model, adv, labels_batch[remaining_indices])\n",
    "        if targeted:\n",
    "            right_improved = right_probs.gt(torch.max(prev_probs[remaining_indices], left_probs))\n",
    "        else:\n",
    "            right_improved = right_probs.lt(torch.min(prev_probs[remaining_indices], left_probs))\n",
    "        probs_k = prev_probs.clone()\n",
    "        # update x depending on which direction improved\n",
    "        if improved.sum() > 0:\n",
    "            left_indices = remaining_indices[improved]\n",
    "            left_mask_remaining = improved.unsqueeze(1).repeat(1, n_dims)\n",
    "            x[left_indices] = left_vec[left_mask_remaining].view(-1, n_dims)\n",
    "            probs_k[left_indices] = left_probs[improved]\n",
    "        if right_improved.sum() > 0:\n",
    "            right_indices = remaining_indices[right_improved]\n",
    "            right_mask_remaining = right_improved.unsqueeze(1).repeat(1, n_dims)\n",
    "            x[right_indices] = right_vec[right_mask_remaining].view(-1, n_dims)\n",
    "            probs_k[right_indices] = right_probs[right_improved]\n",
    "        probs[:, k] = probs_k\n",
    "        queries[:, k] = queries_k\n",
    "        prev_probs = probs[:, k]\n",
    "        if (k + 1) % log_every == 0 or k == max_iters - 1:\n",
    "            print('Iteration %d: queries = %.4f, prob = %.4f, remaining = %.4f' % (\n",
    "                    k + 1, queries.sum(1).mean(), probs[:, k].mean(), remaining.float().mean()))\n",
    "    expanded = (images_batch + trans(expand_vector(x, expand_dims))).clamp(0, 1)\n",
    "    preds = get_preds(model, expanded)\n",
    "    if targeted:\n",
    "        remaining = preds.ne(labels_batch)\n",
    "    else:\n",
    "        remaining = preds.eq(labels_batch)\n",
    "    succs[:, max_iters-1] = 1 - remaining\n",
    "    return x, probs, succs, queries, l2_norms, linf_norms\n",
    "\n",
    "if not os.path.exists(args.result_dir):\n",
    "    os.mkdir(args.result_dir)\n",
    "if not os.path.exists(args.sampled_image_dir):\n",
    "    os.mkdir(args.sampled_image_dir)\n",
    "\n",
    "# load model and dataset\n",
    "model = getattr(models, args.model)(pretrained=True).cuda()\n",
    "model.eval()\n",
    "if args.model.startswith('inception'):\n",
    "    image_size = 299\n",
    "    #testset = dset.ImageFolder(args.data_root + '/val', utils.INCEPTION_TRANSFORM)\n",
    "else:\n",
    "    image_size = 224\n",
    "    #testset = dset.ImageFolder(args.data_root + '/val', utils.IMAGENET_TRANSFORM)\n",
    "\n",
    "# load sampled images or sample new ones\n",
    "# this is to ensure all attacks are run on the same set of correctly classified images\n",
    "batchfile = '%s/images_%s_%d.pth' % (args.sampled_image_dir, args.model, args.num_runs)\n",
    "if os.path.isfile(batchfile):\n",
    "    checkpoint = torch.load(batchfile)\n",
    "    images = checkpoint['images']\n",
    "    labels = checkpoint['labels']\n",
    "else:\n",
    "    images = torch.zeros(args.num_runs, 3, image_size, image_size)\n",
    "    labels = torch.zeros(args.num_runs).long()\n",
    "    preds = labels + 1\n",
    "    while preds.ne(labels).sum() > 0:\n",
    "        idx = torch.arange(0, images.size(0)).long()[preds.ne(labels)]\n",
    "        for i in list(idx):\n",
    "            images[i], labels[i] = testset[random.randint(0, len(testset) - 1)]\n",
    "        preds[idx], _ = utils.get_preds(model, images[idx], 'imagenet', batch_size=args.batch_size)\n",
    "    torch.save({'images': images, 'labels': labels}, batchfile)\n",
    "\n",
    "if args.order == 'rand':\n",
    "    n_dims = 3 * args.freq_dims * args.freq_dims\n",
    "else:\n",
    "    n_dims = 3 * image_size * image_size\n",
    "if args.num_iters > 0:\n",
    "    max_iters = int(min(n_dims, args.num_iters))\n",
    "else:\n",
    "    max_iters = int(n_dims)\n",
    "N = int(math.floor(float(args.num_runs) / float(args.batch_size)))\n",
    "for i in range(N):\n",
    "    upper = min((i + 1) * args.batch_size, args.num_runs)\n",
    "    images_batch = images[(i * args.batch_size):upper]\n",
    "    labels_batch = labels[(i * args.batch_size):upper]\n",
    "    # replace true label with random target labels in case of targeted attack\n",
    "    if args.targeted:\n",
    "        labels_targeted = labels_batch.clone()\n",
    "        while labels_targeted.eq(labels_batch).sum() > 0:\n",
    "            labels_targeted = torch.floor(1000 * torch.rand(labels_batch.size())).long()\n",
    "        labels_batch = labels_targeted\n",
    "    x, probs, succs, queries, l2_norms, linf_norms = dct_attack_batch(\n",
    "        model, images_batch, labels_batch, max_iters, args.freq_dims, args.stride, args.epsilon, order=args.order,\n",
    "        targeted=args.targeted, pixel_attack=args.pixel_attack, log_every=args.log_every)\n",
    "    if i == 0:\n",
    "        all_vecs = x\n",
    "        all_probs = probs\n",
    "        all_succs = succs\n",
    "        all_queries = queries\n",
    "        all_l2_norms = l2_norms\n",
    "        all_linf_norms = linf_norms\n",
    "    else:\n",
    "        all_vecs = torch.cat([all_vecs, x], dim=0)\n",
    "        all_probs = torch.cat([all_probs, probs], dim=0)\n",
    "        all_succs = torch.cat([all_succs, succs], dim=0)\n",
    "        all_queries = torch.cat([all_queries, queries], dim=0)\n",
    "        all_l2_norms = torch.cat([all_l2_norms, l2_norms], dim=0)\n",
    "        all_linf_norms = torch.cat([all_linf_norms, linf_norms], dim=0)\n",
    "    if args.pixel_attack:\n",
    "        prefix = 'pixel'\n",
    "    else:\n",
    "        prefix = 'dct'\n",
    "    if args.targeted:\n",
    "        prefix += '_targeted'\n",
    "    savefile = '%s/%s_%s_%d_%d_%d_%.4f_%s%s.pth' % (\n",
    "        args.result_dir, prefix, args.model, args.num_runs, args.num_iters, freq_dims, args.epsilon, args.order, args.save_suffix)\n",
    "    torch.save({'original': images, 'vecs': all_vecs, 'probs': all_probs, 'succs': all_succs, 'queries': all_queries,\n",
    "                'l2_norms': all_l2_norms, 'linf_norms': all_linf_norms}, savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
